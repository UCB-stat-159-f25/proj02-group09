{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8790b79e-c4fc-497a-b3f6-6fcae79e88f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e30268f-d3d7-42dc-bb10-a1cb3e1dc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7ec398b-b79a-4fc3-960f-8dd8862a968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a436b13-4dce-477d-859c-3ea546273454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total speeches: 246\n",
      "Speeches from 2000 onwards: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Year</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>\\n[Before speaking, the President presented hi...</td>\n",
       "      <td>8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>\\nThe President. Mr. Speaker——\\n[At this point...</td>\n",
       "      <td>8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>\\nThe President. Thank you all very, very much...</td>\n",
       "      <td>7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>\\nThe President. Thank you. Thank you. Thank y...</td>\n",
       "      <td>7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>\\nThe President. Thank you very much. Thank yo...</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         President    Year                                               Text  \\\n",
       "0  Joseph R. Biden  2024.0  \\n[Before speaking, the President presented hi...   \n",
       "1  Joseph R. Biden  2023.0  \\nThe President. Mr. Speaker——\\n[At this point...   \n",
       "2  Joseph R. Biden  2022.0  \\nThe President. Thank you all very, very much...   \n",
       "3  Joseph R. Biden  2021.0  \\nThe President. Thank you. Thank you. Thank y...   \n",
       "4  Donald J. Trump  2020.0  \\nThe President. Thank you very much. Thank yo...   \n",
       "\n",
       "   Word Count  \n",
       "0        8003  \n",
       "1        8978  \n",
       "2        7539  \n",
       "3        7734  \n",
       "4        6169  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the SOTU data\n",
    "sou = pd.read_csv(\"data/SOTU.csv\")\n",
    "print(f\"Total speeches: {len(sou)}\")\n",
    "\n",
    "# Subset for speeches from 2000 onwards (as required by Part 2)\n",
    "sou_2000 = sou[sou['Year'] >= 2000].copy()\n",
    "print(f\"Speeches from 2000 onwards: {len(sou_2000)}\")\n",
    "sou_2000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda0a011-e387-455a-be3f-4d9b46add552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49502b44-1e84-4d6c-a235-03d9219db10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all texts - note this takes ~ 5 minutes to run\n",
    "processed_docs = sou['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e6c34c-5a63-452f-b2e6-66b88915a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [speak, president, present, prepared, remark, ...\n",
      "1    [president, speaker, point, president, turn, f...\n",
      "2    [president, thank, thank, thank, madam, speake...\n",
      "3    [president, thank, thank, thank, good, mitch, ...\n",
      "4    [president, thank, thank, thank, madam, speake...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e80a4-3e23-4bbb-af90-0513358665d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)  \n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755d207-13c6-4a14-988d-bdf10fc5cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=5,       \n",
    "                     random_state=42,    \n",
    "                     passes=10,         \n",
    "                     alpha='auto',       \n",
    "                     eta='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33163383-0622-425f-acbc-c8f939dcf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70d860a8-7d18-47fa-8120-d432ee1558de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "  isthmus\n",
      "  panama\n",
      "  colombia\n",
      "  revolution\n",
      "  colombian\n",
      "  canal\n",
      "  1903\n",
      "  granada\n",
      "  transit\n",
      "  riot\n",
      "\n",
      "Topic 1:\n",
      "  states\n",
      "  government\n",
      "  united\n",
      "  congress\n",
      "  public\n",
      "  country\n",
      "  great\n",
      "  war\n",
      "  state\n",
      "  people\n",
      "\n",
      "Topic 2:\n",
      "  government\n",
      "  states\n",
      "  year\n",
      "  000\n",
      "  united\n",
      "  congress\n",
      "  american\n",
      "  law\n",
      "  department\n",
      "  service\n",
      "\n",
      "Topic 3:\n",
      "  government\n",
      "  war\n",
      "  national\n",
      "  congress\n",
      "  people\n",
      "  great\n",
      "  000\n",
      "  law\n",
      "  nation\n",
      "  public\n",
      "\n",
      "Topic 4:\n",
      "  america\n",
      "  people\n",
      "  world\n",
      "  new\n",
      "  year\n",
      "  american\n",
      "  years\n",
      "  congress\n",
      "  nation\n",
      "  americans\n"
     ]
    }
   ],
   "source": [
    "docs = sou['Text'].to_list()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "n_topics = 5 \n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"\\nTopic {topic_idx}:\")\n",
    "    top_words = topic.argsort()[-10:][::-1]\n",
    "    for i in top_words:\n",
    "        print(\" \", words[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c5cfebc-4eb8-4f8e-8d36-37e23899ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic distribution for the first speech:\n",
      "\n",
      "Topic 0: 0.0000\n",
      "Topic 1: 0.0000\n",
      "Topic 2: 0.0000\n",
      "Topic 3: 0.2081\n",
      "Topic 4: 0.7917\n"
     ]
    }
   ],
   "source": [
    "distribution = lda.transform(X[0])\n",
    "\n",
    "print(\"Topic distribution for the first speech:\\n\")\n",
    "for i, prob in enumerate(distribution[0]):\n",
    "    print(f\"Topic {i}: {prob:.4f}\")\n",
    "\n",
    "sorted_idx = np.argsort(distribution)\n",
    "sorted_probs = distribution[sorted_idx]\n",
    "sorted_labels = [topic_labels[i] for i in sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2381fbb1-890f-478d-a756-9de2145607d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m bars = plt.barh(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43msorted_probs\u001b[49m)), \n\u001b[32m      4\u001b[39m                 sorted_probs, \n\u001b[32m      5\u001b[39m                 color=\u001b[33m'\u001b[39m\u001b[33mlightgray\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      6\u001b[39m                 edgecolor=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m plt.yticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sorted_labels)), sorted_labels, fontsize=\u001b[32m10\u001b[39m)\n\u001b[32m      9\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m\"\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sorted_probs' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "bars = plt.barh(range(len(sorted_probs)), \n",
    "                sorted_probs, \n",
    "                color='lightgray', \n",
    "                edgecolor='black')\n",
    "\n",
    "plt.yticks(range(len(sorted_labels)), sorted_labels, fontsize=10)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.title(\"Topic Probability Distribution\", fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80528e67-ac05-4b86-923d-d1ca1c61aeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
